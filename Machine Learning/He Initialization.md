#machine-learning 

# Definition

> For ReLU and its variant

$n_{in}, n_{out}$ denote the number of input connections and output connections in a layer.

## Normal distribution
$$W \sim N(0,\frac{4}{n_{in}+ n_{out}}) $$

## Uniform distribution
$$W \sim U(\sqrt{\frac{12}{n_{in}+ n_{out}}},\sqrt{\frac{12}{n_{in}+ n_{out}}}) $$

